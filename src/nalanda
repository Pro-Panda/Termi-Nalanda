#! /usr/bin/python

from bs4 import BeautifulSoup
import os
import requests

join = os.path.join

INSTALL_PATH = join(os.path.expanduser("~"), ".nalanda")


def login():
    session = requests.session()
    config = open(join(INSTALL_PATH, "config.txt"), "r")
    config = (config.read()).split("\n")
    session.post("http://nalanda.bits-pilani.ac.in/login/index.php", data={
        "username": config[0],
        "password": config[1],
    })
    return config[2], session


def sub_list_folders(slides_path):
    """Updating Subject List and making folders"""
    name_file = open(join(INSTALL_PATH, "Subjects", "name.txt"), "r")
    url_file = open(join(INSTALL_PATH, "Subjects", "url.txt"), "r")
    url_list = (url_file.read()).split("\n")
    sub_list = (name_file.read()).split("\n")
    for sub in sub_list:
        sub_path = join(slides_path, sub)
        if not os.path.exists(sub_path):
            os.makedirs(sub_path)
    return sub_list, url_list


def get_all_links(sub_urls, session):
    """Getting all relevant links in each subject page"""
    sub_links = [
        BeautifulSoup(session.get(sub).text, "html.parser")
        .find_all("a", {"onclick": ""})
        for sub in sub_urls
    ]
    return sub_links


def sorting_links(sub_links):
    res_urls, news_urls, notice_urls = (
        [[] for x in range(len(sub_links))] for y in range(3))

    for x in range(len(sub_links)):
        for y in range(len(sub_links[x])):
            url = (sub_links[x][y]).get("href")
            if("resource/view.php?id" in url or "folder/view.php?id=" in url):
                res_urls[x].append(url)
            elif("page/view.php?id" in url):
                notice_urls[x].append(
                    [url, sub_links[x][y].contents[1].contents[0]])
            elif("forum/view.php?id" in url):
                news_urls[x].append(url)
            # Needs to be worked upon and added at a later stage.
            # elif("/mod/" in url and "id" in url and "index" not in url):
            #     notice_urls[x].append([url, sub_links[x][y].contents])
    return (notice_urls, news_urls, res_urls)


def bold(text):
    return "\033[1m" + text + "\033[0m"


def get_news(session, sub_names, news_urls):
    subject_news_url = [[] for x in range(len(sub_names))]
    for x in range(len(sub_names)):
        for y in range(len(news_urls[x])):
            result = session.get(news_urls[x][y])
            soup = BeautifulSoup(result.text, "html.parser")
            discussion_list = soup.find_all("tr", "discussion")
            for url in discussion_list:
                if url.find("td", "topic starter pinned"):
                    subject_news_url[x].append([url.contents[0].contents[1].get(
                        "href"), url.contents[0].contents[1].contents[0]])
                else:
                    subject_news_url[x].append([url.contents[0].contents[0].get(
                        "href"), url.contents[0].contents[0].contents[0]])
    return subject_news_url


def find_new(session, sub_names, urls_title, update_type):
    new_urls_title = [[]for x in range(len(sub_names))]
    for x in range(len(sub_names)):
        subject_file = io.open(
            os.path.join(
                INSTALL_PATH,
                update_type,
                sub_names[x]),
            "a+")
        subject_file.seek(0)
        subject_read = (subject_file.read()).split("\n")
        for y in range(len(urls_title[x])):
            if (urls_title[x][y][1] in subject_read):
                pass
            else:
                new_urls_title[x].append(urls_title[x][y])
                subject_file.write("\n" + urls_title[x][y][1])
    return new_urls_title


def term_display(update_list=None, update_type=None,
                 sub_names=[], path=None):
    print (bold(update_type + ":"))
    no_update = sum([len(x) for x in update_list])
    if(no_update == 0):
        print ("\tNo new " + update_type)
        return 0
    if (update_type == "Lectures"):
        [print (bold(sub_names[x]) + " has new updates")
         for x in range(len(sub_names)) if len(update_list[x]) != 0]
        print ("file://" + path)
    else:
        for x in range(len(sub_names)):
            for y in range(len(update_list[x])):
                if(y == 0):
                    print (bold("\n" + sub_names[x] + "-"))
                print ("\t" + bold(str(y + 1)) + ". " + update_list[x][y][1])
                print ("\t\t" + update_list[x][y][0])
    print ("-" * 60 + "\n")


def download(session, sub_names, res_urls, path):
    sub_updates = [[] for x in sub_names]
    for x in range(len(sub_names)):
        done_slides_file = io.open(
            join(
                INSTALL_PATH,
                "Lectures",
                sub_names[x] +
                ".txt"),
            "a+")
        done_slides_file.seek(0)
        done_slides = done_slides_file.read().split("\n")
        for y in range(len(res_urls[x])):
            if (res_urls[x][y] not in done_slides):
                if ("folder/view" in res_urls[x][y]):
                    id_param = res_urls[x][y].split("php")[1]
                    result = session.get(
                        "http://nalanda.bits-pilani.ac.in/mod/folder/download_folder.php" + id_param)
                else:
                    result = session.get(res_urls[x][y])
                file_name = result.headers["content-disposition"].split('e="')[
                    1].split('"')[0]
                with io.open(join(path, sub_names[x], file_name), "wb") as f:
                    f.write(result.content)
                done_slides_file.write(res_urls[x][y] + "\n")
                sub_updates[x].append([])
    return sub_updates


def get_updates(session, sub_names, sorted_urls, path):
    notice_urls, news_urls, res_urls = sorted_urls
    print ("\t\t" + bold("**Nalanda**"))
    unread_update = find_new(
        session, sub_names, notice_urls, "Notices")
    term_display(unread_update, "Notices", sub_names)
    subject_news_url = get_news(session, sub_names, news_urls)
    unread_update = find_new(
        session, sub_names, subject_news_url, "News")
    term_display(unread_update, "News", sub_names)
    update_list = download(session, sub_names, res_urls, path)
    term_display(update_list, "Lectures", sub_names, path)



def main():
    """Displaying notices, news and other announcements, updating slides"""
    try:
        slides_path, session = login()
        sub_names, sub_urls = sub_list_folders(slides_path)
        sub_links = get_all_links(sub_urls, session)
        sorted_links = sorting_links(sub_links)
        get_updates(session, sub_names, sorted_links, slides_path)
    except requests.exceptions.ConnectionError:
        quit("No Internet Connection. Please retry")
    except IOError:
        quit("Unable to read from file. Please reinstall termi-Nalanda")
    except KeyboardInterrupt:
        print("Stopped by user.")


if(__name__ == "__main__"):
    main()
